{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import WordNetLemmatizer\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DistilBertTokenizerFast, AdamW, DistilBertConfig\n",
    "from transformers import DistilBertModel, DistilBertPreTrainedModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class distilBert(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "        self.qa_outputs = nn.Linear(768, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.post_init()\n",
    "\n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "\n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                start_positions=None,\n",
    "                end_positions=None,\n",
    "                output_attentions=None,\n",
    "                output_hidden_states=None, ):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "        hidden_states = distilbert_output[0]\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        logits = self.qa_outputs(hidden_states)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        a, b = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        outputs = (start_logits, end_logits,) + distilbert_output[1:]\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            outputs = (total_loss,) + outputs\n",
    "\n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'start_logits': start_logits,\n",
    "            'end_logits': end_logits\n",
    "        }\n",
    "\n",
    "\n",
    "def get_from_csv(path):\n",
    "    context = []\n",
    "    question = []\n",
    "    answer = []\n",
    "    with open(path) as f:\n",
    "        dataset = f.readlines()\n",
    "        for x in dataset:\n",
    "            data = x.split(' ||| ')\n",
    "            answer.append(data[2].strip())\n",
    "            question.append(data[1])\n",
    "            context.append(data[0].replace('<s>', ''))\n",
    "    dataset = pd.DataFrame(columns=['answer', 'question', 'context'])\n",
    "    for c, x in enumerate(answer):\n",
    "        new_row = pd.DataFrame({'answer': answer[c], 'question': question[c], 'context': context[c]}, index=[0])\n",
    "        dataset = pd.concat([dataset, new_row], ignore_index=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", text)\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "    text = text.split()\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoding):\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.encoding['input_ids'][idx]\n",
    "        attention_mask = self.encoding['attention_mask'][idx]\n",
    "        answer_start = int(self.encoding['answers'][idx]['answer_start'])\n",
    "        answer_end = int(self.encoding['answers'][idx]['answer_end'])\n",
    "        start_position = self.encoding[idx].char_to_token(idx, answer_start)\n",
    "        end_position = self.encoding[idx].char_to_token(idx, answer_end)\n",
    "\n",
    "        if start_position is None:\n",
    "            # start_position = tokenizer.model_max_length\n",
    "            start_position = 0\n",
    "\n",
    "        shift = 1\n",
    "        while end_position is None:\n",
    "            end_position = self.encoding[idx].char_to_token(idx, answer_end - shift)\n",
    "            if start_position == 0:\n",
    "                end_position = 0\n",
    "        sample = {'input_ids': input_ids, 'attention_mask': attention_mask, \"start_positions\": start_position,\n",
    "                  \"end_positions\": end_position}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoding)\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    i = 0\n",
    "    for x in batch:\n",
    "        input_ids.append(x['input_ids'])\n",
    "        attention_masks.append(x['attention_mask'])\n",
    "        start_positions.append(x['start_positions'])\n",
    "        end_positions.append(x['end_positions'])\n",
    "\n",
    "    # return {'input_ids':input_ids,'attention_masks':attention_masks,'start_positions':start_positions,'end_positions':end_positions}\n",
    "    return input_ids, attention_masks, start_positions, end_positions\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def bm25(df_dic):\n",
    "    dataset = pd.DataFrame(columns=['answer', 'question', 'context'])\n",
    "    for i in range(0, len(df_dic) - 1):\n",
    "        context = df_dic.loc[i][2]\n",
    "        answer = df_dic.loc[i][0]\n",
    "        question = df_dic.loc[i][1]\n",
    "        sentences = context.split('</s>')[:-1]\n",
    "        corpus_sent = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            preprocessedsent = preprocess(sent)\n",
    "            corpus_sent.append(preprocessedsent)\n",
    "        else:\n",
    "            corpus_sent.append(\" \")\n",
    "\n",
    "        query = preprocess(question)\n",
    "\n",
    "        tokenized_query = query.split(\" \")\n",
    "\n",
    "        tokenized_corpus_abstract = [doc.split(\" \") for doc in corpus_sent]\n",
    "\n",
    "        bm25_abstract = BM25Okapi(tokenized_corpus_abstract)\n",
    "        doc_scores_abstracts = bm25_abstract.get_scores(tokenized_query)\n",
    "\n",
    "        doc_scores = doc_scores_abstracts\n",
    "\n",
    "        score_dict = dict(zip([x + '</s>' for x in sentences], doc_scores))\n",
    "\n",
    "        doc_ranking = sorted(score_dict, reverse=True)\n",
    "        context = ''.join(doc_ranking)\n",
    "        start_idx = context.find(answer)\n",
    "        new_row = pd.DataFrame({'answer': answer, 'question': question, 'context': context, 'start': start_idx},\n",
    "                               index=[0])\n",
    "        dataset = pd.concat([dataset, new_row], ignore_index=True)\n",
    "    # new_row.to_pickle('dataset.pkl')\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_end_idx(answers, contexts, starts):\n",
    "    new_answers = []\n",
    "    for answer, context, start in tqdm(zip(answers, contexts, starts)):\n",
    "        gold_text = answer\n",
    "        start_idx = start\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "        answer_start = start_idx\n",
    "\n",
    "        if context[int(start_idx):int(end_idx)] == gold_text:\n",
    "            answer_end = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx - n:end_idx - n] == gold_text:\n",
    "                    answer_start = start_idx - n\n",
    "                    answer_end = end_idx - n\n",
    "        answer = {'text': gold_text, 'answer_start': answer_start, 'answer_end': answer_end}\n",
    "        new_answers.append(answer)\n",
    "    return new_answers\n",
    "\n",
    "\n",
    "def prep_data(dataset):\n",
    "    questions = dataset['question']\n",
    "    contexts = dataset['context']\n",
    "    answers = add_end_idx(\n",
    "        dataset['answer'],\n",
    "        contexts,\n",
    "        dataset['start']\n",
    "    )\n",
    "    return {\n",
    "        'question': questions,\n",
    "        'context': contexts,\n",
    "        'answer': answers\n",
    "    }\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kuro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kuro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/kuro/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [41], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwordnet\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124momw-1.4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mget_from_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/home/kuro/PycharmProjects/sequence_tagging/NLP2/data/train.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m rank \u001B[38;5;241m=\u001B[39m bm25(dataset)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m dataset\n",
      "Cell \u001B[0;32mIn [40], line 97\u001B[0m, in \u001B[0;36mget_from_csv\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(answer):\n\u001B[1;32m     96\u001B[0m     new_row \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m'\u001B[39m: answer[c], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m'\u001B[39m: question[c], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m'\u001B[39m: context[c]}, index\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 97\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_row\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dataset\n",
      "File \u001B[0;32m~/PycharmProjects/sequence_tagging/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/sequence_tagging/venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:381\u001B[0m, in \u001B[0;36mconcat\u001B[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03mConcatenate pandas objects along a particular axis.\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m1   3   4\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    368\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[1;32m    369\u001B[0m     objs,\n\u001B[1;32m    370\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    378\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[1;32m    379\u001B[0m )\n\u001B[0;32m--> 381\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/sequence_tagging/venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:616\u001B[0m, in \u001B[0;36m_Concatenator.get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    612\u001B[0m             indexers[ax] \u001B[38;5;241m=\u001B[39m obj_labels\u001B[38;5;241m.\u001B[39mget_indexer(new_labels)\n\u001B[1;32m    614\u001B[0m     mgrs_indexers\u001B[38;5;241m.\u001B[39mappend((obj\u001B[38;5;241m.\u001B[39m_mgr, indexers))\n\u001B[0;32m--> 616\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[43mconcatenate_managers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmgrs_indexers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcat_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbm_axis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy:\n\u001B[1;32m    620\u001B[0m     new_data\u001B[38;5;241m.\u001B[39m_consolidate_inplace()\n",
      "File \u001B[0;32m~/PycharmProjects/sequence_tagging/venv/lib/python3.10/site-packages/pandas/core/internals/concat.py:223\u001B[0m, in \u001B[0;36mconcatenate_managers\u001B[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001B[0m\n\u001B[1;32m    217\u001B[0m vals \u001B[38;5;241m=\u001B[39m [ju\u001B[38;5;241m.\u001B[39mblock\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mfor\u001B[39;00m ju \u001B[38;5;129;01min\u001B[39;00m join_units]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m blk\u001B[38;5;241m.\u001B[39mis_extension:\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001B[39;00m\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m#  we can use np.concatenate, which is more performant\u001B[39;00m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m#  than concat_compat\u001B[39;00m\n\u001B[0;32m--> 223\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001B[39;00m\n\u001B[1;32m    226\u001B[0m     values \u001B[38;5;241m=\u001B[39m concat_compat(vals, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "dataset = get_from_csv('/home/kuro/PycharmProjects/sequence_tagging/NLP2/data/train.txt')\n",
    "rank = bm25(dataset)\n",
    "del dataset\n",
    "gc.collect()\n",
    "dataset = prep_data(rank)\n",
    "questions = dataset['question'].to_list()\n",
    "contexts = dataset['context'].to_list()\n",
    "answers = dataset['answer']\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "train_encoding = tokenizer(contexts, questions, truncation=True, padding=True, max_length=512)\n",
    "train_encoding['answers'] = answers\n",
    "dataset = Dataset(train_encoding)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model = distilBert(DistilBertConfig())\n",
    "model.to(device)\n",
    "model.train()\n",
    "model = torch.load('/home/kuro/PycharmProjects/sequence_tagging/qa-bert')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fct = CrossEntropyLoss()\n",
    "training_epoch = 1\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_batch)\n",
    "accs=[]\n",
    "losses=[]\n",
    "for epoch in range(50):\n",
    "    loop = tqdm(loader)\n",
    "    for a,b,c,d in loop:\n",
    "        acc=[]\n",
    "        optim.zero_grad()\n",
    "        input_ids = torch.as_tensor(a).to(device)\n",
    "        attention_mask = torch.as_tensor(b).to(device)\n",
    "        start_positions =torch.as_tensor( c).to(device)\n",
    "        end_positions = torch.as_tensor(d).to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        start_pred = torch.argmax(outputs['start_logits'],dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'],dim=1)\n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "        accuracy = sum(acc)/len(acc)\n",
    "        accs.append(accuracy)\n",
    "        loss = outputs['loss']\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f'Epoch : {epoch} loss : {loss.item()} accuracy: {accuracy}')\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3+ElEQVR4nO3deXhU9cH28e+Z7AlJ2JdAkEUUCBAIycwEWrWPVqvWqnUvS1jiiiCiVahVWxVR61ZFEQiEsIhafVBrtS5YQQWyEPZ9J4BhJyEJ2WbO+0f78NZWhMAkv5nM/bmu+cNDhrkvRpjvNedkYtm2bSMiIiLiAw7TA0RERKTxUFiIiIiIzygsRERExGcUFiIiIuIzCgsRERHxGYWFiIiI+IzCQkRERHxGYSEiIiI+E9rQD+j1etm3bx+xsbFYltXQDy8iIiJnwbZtjh8/TkJCAg7Hqd+XaPCw2LdvH4mJiQ39sCIiIuIDRUVFdOjQ4ZS/3uBhERsbC/xzWFxcXEM/vIiIiJyF0tJSEhMTT76On0qDh8X/nf6Ii4tTWIiIiASY013GoIs3RURExGcUFiIiIuIzCgsRERHxGYWFiIiI+IzCQkRERHxGYSEiIiI+o7AQERERn1FYiIiIiM8oLERERMRnFBYiIiLiMwoLERER8RmFhYiIiPiMwkJERKQRsL1ect9+ltxXhxrd0eA/3VRERER8q/TYYbZmDcNVthiANYsX0Pui641sUViIiIgEsC0rFhPzYSYp9n6q7RAKLxiL6yfXGtujsBAREQlAttdL7ltPk7LpRcItD/us1pT9ajrulEuM7lJYiIiIBJiSw/vZPmMY7oolYEFhzE/pmjmLhGYtTU9TWIiIiASSjQULafrRnfTjINV2KCt6PIjz5oexHP7x/RgKCxERkQDg9XjIm/8E/be8SpjlYY/VlsrrZ+BK/onpad+jsBAREfFzRw9+x+6ZGbhP5IIFy2N/xgWZM+kQ39z0tP+isBAREfFjG3I/pfknd5PMYarsMFb2Go/zhnF+c+rjPyksRERE/JDX4yF37qOkbZ9CqOWlyEqg+oZsXL3dpqf9KIWFiIiInzm8fw97s4eSXrkcLCiI+zk9bs8iJrap6WmnpbAQERHxI+u+/RutPx9FH45ywg5nbfLvSb1utN+e+vhPCgsRERE/4KmtJW/273DumkaIZbPTkQg3zSKtR6rpaXWisBARETHsUPFuirOHkF61EizIa3oVvTLfILpJvOlpdaawEBERMWjN4g9o9+UYenGMCjuCdSl/wHntPaZnnTWFhYiIiAG1NdXk5zyMqygbh2Wzw9EJxy05pF3Y1/S0c6KwEBERaWAH9u7gUM4Q0qvXgAW5zX9FcuYUIqObmJ52zhQWIiIiDWj1P94lcdH99KSUcjuSDc6ncF19u+lZPqOwEBERaQA11VUUZD9I+nezAdgW0oXw22aTen5vw8t8S2EhIiJSz4qLtnJs9hDSa9YDkNvy1ySPnExkVIzhZb6nsBAREalHK7+YT6dvHqQ7ZRy3o9jinoTryuGmZ9UbhYWIiEg9qK6qpHDmWNz75wOwJbQb0b+ZQ0qXHoaX1S+FhYiIiI/t27mJsrmDcdduBmBZ61tIGfkK4RGRhpfVP4WFiIiIDxV+Oofzlz5MAuWUEsO2Ac/hvnyw6VkNRmEhIiLiA1WVFaycMRrXwXcB2BTanbghs+l33oWGlzUshYWIiMg52rt9HRXzhuLybAVgWdtB9B/xEmHhEYaXNTyFhYiIyDlY/vEMLsx9hPbWCY4Sy+6Lnsf9P7eanmWMwkJEROQsVJ4oZ1XWPbgOvw8WbAhLonnGHJI7dDU9zSiFhYiISB0VbVlF9VsZuDw78NoWuR0ySBv2J0LDwk1PM05hISIiUgcFH75Bz+WPEW1VcYQ49v7Pn0m/+NemZ/kNhYWIiMgZOFF+nDVZd+I8+jewYF14H1oPm0PvhE6mp/kVhYWIiMhp7NpYiPedYTi9u/556qNjJs6MZwgJ1cvof9KfiIiIyI/If38ySSueINqq4hBNKf75q6T/5FemZ/kthYWIiMgPqCgrYd3020kr+RQsWBPRj3bD59CrbaLpaX5NYSEiIvIfdqzLxfHeCNK8e/DYFnmd78I5+Cmd+jgDjrp8scfj4dFHH6Vz585ERUXRtWtXnnzySWzbrq99IiIiDcb2esl77yXavXM153n3cIDmbPrFfNKH6XqKM1WnP6Vnn32WKVOmkJOTQ1JSEgUFBQwfPpz4+HjGjBlTXxtFRETqXVnpUTZmZeIs/QIsWB2ZRocROfRs3d70tIBSp7BYsmQJ1157LVdffTUAnTp1Yv78+eTl5dXLOBERkYawbfUSwheMJNXeR63toKDrvTgH/QFHSIjpaQGnTqdCBgwYwMKFC9m8+Z8/X37VqlV88803XHnllae8T1VVFaWlpd+7iYiI+APb6yX3nefo8N6vSLT3UUxLtl79Du6hTyoqzlKd3rEYP348paWldO/enZCQEDweDxMnTmTQoEGnvM+kSZP44x//eM5DRUREfKn02GG2Zg3HVbYILFgZnU6nEbPo3rKt6WkBrU7vWLzzzjvMmzePN998k8LCQnJycnj++efJyck55X0mTJhASUnJyVtRUdE5jxYRETkXW1Ys5vif00kpW0SNHcKybg+Q/ODHNFVUnDPLrsO3dCQmJjJ+/HhGjRp18thTTz3F3Llz2bhx4xn9HqWlpcTHx1NSUkJcXFzdF4uIiJwl2+sl9+1JpGx8gXDLwz6rNWXXTOeClEtMT/N7Z/r6XadTIRUVFTgc33+TIyQkBK/Xe3YrRUREGkjJkYNsz8rAXfEtWLAi5id0ycwhoVlL09MalTqFxTXXXMPEiRPp2LEjSUlJrFixghdffJERI0bU1z4REZFztqngS+I+uoN+HKTaDmVFjwdx3vwwlqNOVwTIGajTqZDjx4/z6KOPsmDBAg4cOEBCQgK33XYbjz32GOHhZ/Yz6HUqREREGorX4yFv/pP03/IKYZaHPVZbTlybRbe+PzU9LeCc6et3ncLCFxQWIiLSEI4dKmbXjKEkn8gFYHmTS+iWOZO4pi0MLwtM9XKNhYiISCDYmPsZzT65i2QOU2WHsTLpYZw3PqBTHw1AYSEiIo2G1+Mhd+5jpG1/nVDLS5GVQPUN2bh6u01PCxoKCxERaRQO79/D3uwM0isLwIKCuMvonplFk7hmpqcFFYWFiIgEvHVLPqb1Z/fQh6OcsMNZ0+cR0q4fo1MfBigsREQkYHlqa8mb8wjOnVMJsWx2ORLx3piNs2ea6WlBS2EhIiIB6VDxboqzh5BetRIsyG96JUmZU4luEm96WlBTWIiISMBZ+/UHtF04hl4co8KOYF2/x0m7btTp7yj1TmEhIiIBo7ammoKc8TiLZuKwbHY4zsNx8yzSuqeYnib/orAQEZGAcHDfTg7OGoy7eg1YkNf8GvpkvkFkdBPT0+TfKCxERMTvrf7HuyQuup+elFJuR7Ih7Umcv7zD9Cz5AQoLERHxW7U11eRnP0D6vtkAbAvpQvits0jtlmx4mZyKwkJERPxScdFWjs4eQnrNegByW/6a5JGTiYyKMbxMfozCQkRE/M7KhW/R6esH6EEZx+0oNrsm4bpquOlZcgYUFiIi4jeqqyopnDkW9/75AGwJOZ/oQbPp3yXJ8DI5UwoLERHxC/t2buL43CG4azcBsKz1zfQb8WciIqMNL5O6UFiIiIhxKz6bS9clD5FAOaXEsG3Ac7gvH2x6lpwFhYWIiBhTVVnBihljcB/8CwCbQi8kdvAc+nW60PAyOVsKCxERMWLv9nVUzBuK27MVgGVtbiNlxMuER0QaXibnQmEhIiINbvnH2VyQO4H21gmO0YSdP30B96W3mp4lPqCwEBGRBlN5opxVWffgOvw+WLAhrCfNhs6hb+L5pqeJjygsRESkQRRtWUX1Wxm4PDsAWJqQQeqwPxEWHmF4mfiSwkJEROpdwV+n0qPgMWKsSo4SR9ElL5N+yQ2mZ0k9UFiIiEi9OVF+nDVZd+E8+hFYsC68N62HzaVPQifT06SeKCxERKRe7NpYiPedYTi9u/DaFrkdR5I2dBKhYeGmp0k9UliIiIjP5b8/maQVTxBtVXGIphRf9grpP73W9CxpAAoLERHxmYqyEtZNv4O0kr+DBWsj+tJ2+Bx6te1oepo0EIWFiIj4xI71+TjeHUaadw8e2yKv0504h0wkJFQvNcFEz7aIiJwT2+slf8Gf6bN6IpFWDQdozsErXiN9wFWmp4kBCgsRETlrZaVH2ZiVibP0C7BgdWQqHUbMJql1e9PTxBCFhYiInJVtq5cQvmAkqfY+am0H+V3uwTX4CRwhIaaniUEKCxERqRPb6yXv3efpu+45Iqwa9tOCo1e9QbrrctPTxA8oLERE5IyVHjvM1qzhuMoWgQUro9x0GplD95ZtTU8TP6GwEBGRM7JlxWKiP8wkxd5PjR3C8m5jcP3mMSyHw/Q08SMKCxER+VG210vu25NI2fgC4ZaH72hFyTVTcadeanqa+CGFhYiInFLJkYNsnzEMd/k3YMGK6IF0ycyhXfNWpqeJn1JYiIjID9pU8CVxH91BPw5SbYdQ2P0BXLdM0KkP+VEKCxER+R7b6yX3zSfov+UVwiwPe602VFybhbvfRaanSQBQWIiIyEnHDhWzc0YG7hPLwILCJhdzfmY27Zu2MD1NAoTCQkREANiY+xnNPrmLvhymyg5jZdJDOG98UKc+pE4UFiIiQc7r8ZA79zHStr9OqOWlyEqg+tczcPUZYHqaBCCFhYhIEDtyYC97ZmaQXpkPFhTEXUb3zCyaxDUzPU0ClMJCRCRIrVvyMa0+G0UfjlBph7G6zyOkXX+fTn3IOVFYiIgEGU9tLXlzHsG5cyohls0uRwe8N8zEmeQyPU0aAYWFiEgQOVS8m+LsIaRXrQQL8uN/QdLt04huEm96mjQSCgsRkSCx9usPaLtwDL04RoUdwbp+j5F23b2mZ0kjo7AQEWnkPLW15M96CGfRTByWzQ7HeThuyiatR3/T06QRUliIiDRiB/ft5MCswbir14AFec1+Se/MN4iKiTU9TRophYWISCO1+qv3SPxqLEmUUm5HsiH1CZzX3Gl6ljRyCgsRkUamtqaa/OwHSN83G4BtIZ0JvzWH1G7JhpdJMFBYiIg0IsVFWzk6ewjpNesByG1xHcmZrxMZFWN4mQQLhYWISCOx6su3OG/xA/SgjON2FJtdE3FdNdL0LAkyCgsRkQBXU13F8hn34d4/H4AtIecTPWg2/bskGV4mwUhhISISwPbt3MTxuUNw124CYFmrm+g38hUiIqMNL5NgpbAQEQlQKz6bS9clD5FAOaXEsDX9WdxXDDE9S4KcwkJEJMBUVVawYsYY3Af/AsDm0AtoMnguKZ0uNLxMRGEhIhJQ9m5fR8W8obg9WwFY1uY2Uka8THhEpOFlIv+ksBARCRDLP87mgtwJtLdOcIwm7PzJ87gvu830LJHvUViIiPi5yhPlrMq6B9fh98GCjWE9aTp0Dn0Tzzc9TeS/KCxERPxY0dY1VM8fisuzHYClCUNJHfY8YeERhpeJ/DCFhYiInyr4aBo98h8lxqrkKHEUXfwS6T+70fQskR+lsBAR8TMnyo+zJusunEc/AgvWh/emZcYc+rTvbHqayGkpLERE/MiujYV43xmG07sLr22RlziC1IxnCA0LNz1N5IwoLERE/ET++5NJWvEE0VYVh2jKd5e+gvuia03PEqkTR13vsHfvXgYPHkyLFi2Iioqid+/eFBQU1Mc2EZGgUFFWQv5Lt5C28hGirSrWRvSFu76mt6JCAlCd3rE4evQoAwcO5Gc/+xmffPIJrVq1YsuWLTRr1qy+9omINGo71ufjeHc4ad4iPLZFXqc7cQ6ZSEio3lCWwFSn/3OfffZZEhMTyc7OPnmsc2ddTCQiUle210v+glfos/opIq0aDtKMA5e/RvrAq01PEzkndToV8uGHH5KamspNN91E69at6devH9OnT//R+1RVVVFaWvq9m4hIMCsrPcryl2/CueZxIq0aVkem4rj7G5IUFdII1Ckstm/fzpQpU+jWrRuffvopd999N2PGjCEnJ+eU95k0aRLx8fEnb4mJiec8WkQkUG1bs4yjLw0gtfQLam0HSzvfS6/ffkaLNh1MTxPxCcu2bftMvzg8PJzU1FSWLFly8tiYMWPIz89n6dKlP3ifqqoqqqqqTv53aWkpiYmJlJSUEBcXdw7TRUQCh+31kvfuC/Rd9ywRVg37acGRK6fQw3WF6WkiZ6S0tJT4+PjTvn7X6RqLdu3a0bNnz+8d69GjB++9994p7xMREUFEhD56VkSCV+mxw2zJGoGr7CuwYFWUi/NGzqZHy7amp4n4XJ3CYuDAgWzatOl7xzZv3sx5553n01EiIo3FlpVfE/3BSPrb+6mxQ1jebQzO2x7FERJieppIvahTWNx///0MGDCAp59+mptvvpm8vDymTZvGtGnT6mufiEhAsr1ect9+hpSNLxBu1fIdrSi5Ziru1EtNTxOpV3W6xgLgo48+YsKECWzZsoXOnTszbtw4br/99jO+/5meoxERCVQlRw6yfcYw+pV/A8CK6IF0ycwhvnkrw8tEzt6Zvn7XOSzOlcJCRBqzTQVfEvu3O0mwD1Bth1DY/QFct0zActT5g45F/Eq9XLwpIiI/zPZ6yZ3/JP03/5kwy8Neqw0V12bh7neR6WkiDUphISJyjo4dKmbnjAzcJ5aBBYVNLuL8zFm0b9rC9DSRBqewEBE5BxvzPqfpx3fRl0NU2WGsTHoI540P6tSHBC2FhYjIWfB6POTO+wNp2yYTankpshKo/vUMXH0GmJ4mYpTCQkSkjo4c2MuemRmkV+aDBQWxl9L99hk0idNPehZRWIiI1MH6pZ/Q8tN76MMRKu0wVvd5hLTr79OpD5F/UViIiJwBT20teXMewblzKiGWzS5HB7w3zMSZ5DI9TcSvKCxERE7jUHER32UPIb1qBViQH38FPTOnERPb1PQ0Eb+jsBAR+RFrv/mQtl+MpjfHqLAjWNfvMdKuu9f0LBG/pbAQEfkBntpa8nIexrV7Bg7LZqejI9ZNs0jr0d/0NBG/prAQEfkPB/ft5MCsIaRXrwYL8pr9kt6ZbxAVE2t6mojfU1iIiPybNYv+l/b/uI8kSim3I9mQ+gTOa+40PUskYCgsRESA2ppq8rMfJH1fDgDbQjoTfmsOqd2SDS8TCSwKCxEJevv3bONIzhDSa9YBkNviOpIzXycyKsbwMpHAo7AQkaC26su36Lj4QXpwnDI7ik2uibiuGml6lkjAUliISFCqqa5i+cz7cRfPA2BLyPlED5pN/y5JhpeJBDaFhYgEne92baJ0zlDctRsByG11I31HvkpEZLThZSKBT2EhIkFlxWdz6brkIdpRTikxbE1/FtcVQ0zPEmk0FBYiEhSqqyopnDEa94F3ANgcegFNBs8lpdOFhpeJNC4KCxFp9PZu30DFm0Nw124BYFmb20gZ8TLhEZGGl4k0PgoLEWnUCj/JptuyCbS3TnCMJuz8yfO4L7vN9CyRRkthISKNUuWJclbNuBfXof8FCzaG9aTpkNn07djN9DSRRk1hISKNTtHWNVTNz8Dl2QbA0oShpA57nrDwCMPLRBo/hYWINCoFf5tOj7zfE2NVcpQ4ii5+ifSf3Wh6lkjQUFiISKNQWVHGqqy7cR35ECxYH96blhlz6NO+s+lpIkFFYSEiAW/XppV4387A5d2J17bITRxOWsazhIaFm54mEnQUFiIS0PI/eJ2kwj8QbVVxiKZ8d+krpF90relZIkFLYSEiAamirIS1WXfhPPYxWLA2oi9th8+hd9uOpqeJBDWFhYgEnJ0bCuAvw3B6i/DYFnnn3YFz6NOEhOqfNBHT9LdQRAKG7fVS8P6r9Fr1FFFWNQdpxoHLXyN94NWmp4nIvygsRCQglB8/xobpI0kr/QIsWB3Zn/bDZ5PUpoPpaSLybxQWIuL3tq1ZRvj/DifV3ket7SC/y924Bj+JIyTE9DQR+Q8KCxHxW7bXS957L9J37TNEWDXspwVHrppCuusK09NE5BQUFiLil46XHGFz1ghcx/8BFqyKctFxRA49WrUzPU1EfoTCQkT8ztZV3xD5/kj628XU2CEs7zYa522P6dSHSABQWIiI37C9XvLeeZZ+G54n3KrlO1pRcs1U3KmXmp4mImdIYSEifqHk6CG2ZQ3DVf41WLAiegBdMmfTrnkr09NEpA4UFiJi3ObCr2jy19tJsQ9QbYdQeOE4XLf+DsvhMD1NROpIYSEixtheL7nznyJl88uEWx72WW0o+9V03CkXm54mImdJYSEiRpQc3s/2GcNwVywBCwqbXMT5mbNIaNrC9DQROQcKCxFpcBvzv6Dp3+6kH4eotkNZ0fMhnDf9Vqc+RBoBhYWINBivx0PevD+Qum0yoZaXPVY7Kq+fgSt5oOlpIuIjCgsRaRBHDuylaGYG7sp8sKAg9lK63z6DJnHNTE8TER9SWIhIvVu/7O+0/PvdJHOESjuM1b1/R9qvx+rUh0gjpLAQkXrj9XjInfMIzh1vEGLZ7Ha0p/bX2Th7uUxPE5F6orAQkXpxqLiI77KHkl5VCBbkx19Oz8zpxMQ2NT1NROqRwkJEfG7tNx/S9ovR9OYYFXYEa/s+ivP60aZniUgDUFiIiM94amvJyxmPa3cWDstmp6Mj1k2zcPbob3qaiDQQhYWI+MShfbvYP2sI6dWrwIK8ZlfTO3MqUTGxpqeJSANSWIjIOVuzeAEJX95HEiVU2BGs7/8Ezl/dZXqWiBigsBCRs1ZbU03+rIdw7ZmFw7LZ7uhE6K05pF7Q1/Q0ETFEYSEiZ2X/nm0czhlKes1asCC3xXUkj3yNyOgmpqeJiEEKCxGps1VfvkPHxePoyXHK7Cg2OZ/CdXWm6Vki4gcUFiJyxmqqq1g+837cxfMA2BrSlcjbZtP//F6Gl4mIv1BYiMgZKd69hWOzh+Cu3QBAbqsb6TvyVSIiow0vExF/orAQkdNa+fmbdP72QdpSTinRbEt/BtcVGaZniYgfUliIyClVV1VSOGMM7gNvA7A59AKaDJpDv87dDS8TEX+lsBCRH7Rvx0bK5g3BXbsZgGVtbiVlxJ8Jj4g0vExE/JnCQkT+y4pPc+i6dDwJVFBCDDsGPo/7578xPUtEAoDCQkROqjxRzqoZo3Edeg+AjaE9aDp0Dn07djO8TEQChcJCRADYs3UtlfOH4vJsA2Bpu8GkDn+RsPAIw8tEJJAoLESE5X/L4sK839PEOsFR4th98Yuk/+wm07NEJAApLESCWGVFGatm3IPr8AdgwfqwXrQcNpfk9p1NTxORAKWwEAlSuzevpPatDFzenXhti9zE4aRlPEtoWLjpaSISwBzncudnnnkGy7IYO3asj+aISEMo+HAKLeddThfvTg4Tz7pLs0nPfElRISLn7KzfscjPz2fq1Kn06dPHl3tEpB6dKD/Omul34Dz2MViwLjyZNsPm0DvhPNPTRKSROKt3LMrKyhg0aBDTp0+nWbNmvt4kIvVg14bl7H8hHeexj/HaFks73kH3h76kpaJCRHzorMJi1KhRXH311Vx22WWn/dqqqipKS0u/dxORhmN7veQteIXWb/2CTt4iDtGU9ZfPIX3EnwgJ1WVWIuJbdf5X5a233qKwsJD8/Pwz+vpJkybxxz/+sc7DROTclR8/xvqs23GWfAYWrIlIIWHEHHq16WB6mog0UnV6x6KoqIj77ruPefPmERl5Zj8vYMKECZSUlJy8FRUVndVQEamb7WtzOfzSANJKPsNjWyzrNIqkh76ghaJCROqRZdu2faZf/P7773P99dcTEhJy8pjH48GyLBwOB1VVVd/7tR9SWlpKfHw8JSUlxMXFnf1yEflBttdL3nsvkbx2EpFWDQdozqFfTKGn+xemp4lIADvT1+86nQq59NJLWbNmzfeODR8+nO7du/Pwww+fNipEpH4dLznC5qyRuI5/CRasikyj48g59GzVzvQ0EQkSdQqL2NhYevXq9b1jMTExtGjR4r+Oi0jD2rrqWyLfH0l/+ztqbQcF54/G+ZvHcSj4RaQB6ZJwkQBne73k/eU5+q3/E+FWLcW04tgv38Cddvrv2hIR8bVzDouvvvrKBzNE5GyUHD3EthnDcZUtBgtWRA+gy8hZtG3RxvQ0EQlSesdCJEBtLlxEk7/eToq9n2o7hMIL78d16yNYjnP6pH4RkXOisBAJMLbXS+5bE0nZ9BLhlod9VhvKfjUdd8rFpqeJiCgsRAJJyeH9bJ8xDHfFErCgMOYiumZmk9CspelpIiKAwkIkYGzM/4Kmf7uLfhyk2g5lRc/f4rzpIZ36EBG/orAQ8XNej4e8N/9I/62TCbM87LHaUnn9DFzJPzE9TUTkvygsRPzY0YPfsXvmUNwn8sCC5bE/44LMmXSIb256mojID1JYiPip9cv+Tsu/300yR6i0w1jVawLOG+7XqQ8R8WsKCxE/4/V4yJvzKKk7phBqedntaE/tr7Nx9XKZniYicloKCxE/cnj/HvbNHIK7qhAsyI+/nJ6Z04mJbWp6mojIGVFYiPiJtd/+lbaf30tvjnHCDmdN30dJu/ZenfoQkYCisBAxzFNbS97sCTh3TSfEstnpSISbZuHskWp6mohInSksRAw6tG8XxTlDSa9aCRbkNb2K3rdPIyom1vQ0EZGzorAQMWTN4gUkfHkfvSihwo5gXcofcF57j+lZIiLnRGEh0sBqa6rJn/UQrj2zcFg22x2dCLklh7QL+5qeJiJyzhQWIg3owN4dHJo1mPSatWBBbotrSR75OpHRTUxPExHxCYWFSANZ9Y+/0HHROHpSSpkdxUbnk7iuvt30LBERn1JYiNSzmuoqCrLHkf7dXAC2hnQl8rbZpJ7fy/AyERHfU1iI1KPi3Vs4NnsI6bUbAMhteQPJI18lMirG8DIRkfqhsBCpJys/f5PO3z5IW8opJZqt7km4fjHM9CwRkXqlsBDxseqqSgpn3od7/1sAbA69gJjfzCalSw/Dy0RE6p/CQsSH9u3YSNm8IbhrNwOwrPUtpIx8hfCISMPLREQahsJCxEdWfJpD16XjSaCCEmLYMfB53D//jelZIiINSmEhco6qKitYmXUvrkPvAbAxtAfxQ3Loe96FhpeJiDQ8hYXIOdizdS2V84fi8mwDYGm7waQOf5Gw8AjDy0REzFBYiJyl5X/L4sK839PEOsFRYtl90Yuk/8/NpmeJiBilsBCpo8qKMlbNuAfX4Q/Agg1hSTTPmENyh66mp4mIGKewEKmD3ZtXUvtWBi7vTry2RW6HYaQNe47QsHDT00RE/ILCQuQMFXw4hZ7LHyfaquIIcey99BXSL7re9CwREb+isBA5jRPlx1kz/Q6cxz4GC9aFJ9Nm2Bx6J5xnepqIiN9RWIj8iF0blmP/ZRhO7+5/nvo473acQycREqq/OiIiP0T/OoqcQt6CV+m98gmirGoO0ZTiyyeTPvAa07NERPyawkLkP5QfP8b6rDtwlnwKFqyJSKHd8Nn0aptoepqIiN9TWIj8m+1rcwn53xGkeffgsS3yO9+Dc8iTOEJCTE8TEQkICgsRwPZ6yXvvJZLXTiLSquEAzTl05RTc7l+YniYiElAUFhL0jpccYXPWSFzHvwQLVkWm0XHkHHq2amd6mohIwFFYSFDbuupbIt8fSX/7O2ptBwXnj8b5m8d16kNE5CwpLCQo2V4veX/5E/3WP0e4VUsxLTn2y6m40y4zPU1EJKApLCTolB47zNasYbjKFoMFK6IH0GXkLNq2aGN6mohIwFNYSFDZXLiIJn+9nRR7P9V2CIUXjMV12++xHA7T00REGgWFhQQF2+sl962nSdn0IuGWh31Wa8p+NR13yiWmp4mINCoKC2n0Sg7vZ/uMYbgrloAFhTE/pWvmLBKatTQ9TUSk0VFYSKO2sWAhTT+6k34cpNoOZUXP3+K86SGd+hARqScKC2mUvB4PefOfoP+WVwmzPOyx2lJ5/QxcyT8xPU1EpFFTWEijc/Tgd+yemYH7RC5YsDz2Z1yQOZMO8c1NTxMRafQUFtKobMj9lOaf3E0yh6myw1jZawLOG+7XqQ8RkQaisJBGwevxkDv3UdK2TyHU8lJkJVBz4yxcvVymp4mIBBWFhQS8w/v3sDd7KOmVy8GCgrif0+P2LGJim5qeJiISdBQWEtDWffs3Wn8+ij4c5YQdztrk35N63Wid+hARMURhIQHJU1tL3uzf4dw1jRDLZqcjEW6aRVqPVNPTRESCmsJCAs6h4t0UZw8hvWolWJDX9Cp6Zb5BdJN409NERIKewkICyprFH5Dw5Wh6UUKFHcG6lD/gvPYe07NERORfFBYSEGprqsnPeRhXUTYOy2aHoxOOW3JIu7Cv6WkiIvJvFBbi9w7s3cGhnCGkV68BC3Kb/4rkzClERjcxPU1ERP6DwkL82up/vEviovvpSSnldiQbnE/huvp207NEROQUFBbil2qqqyjIfpD072YDsDWkKxG35ZB6fm/Dy0RE5McoLMTvFBdt5djsIaTXrAcgt+WvSR45mcioGMPLRETkdBQW4ldWfjGfTt88SHfKOG5HscU9CdeVw03PEhGRM6SwEL9QXVVJ4cyxuPfPB2BLaDeifzOHlC49DC8TEZG6UFiIcft2bqJs7mDctZsBWNb6FlJGvkJ4RKThZSIiUlcKCzGq8NM5nL/0YRIop5QYtg14Dvflg03PEhGRs6SwECOqKitYOWM0roPvArAptDtxQ2bT77wLDS8TEZFzobCQBrd3+zoq5g3F5dkKwLK2g+g/4iXCwiMMLxMRkXOlsJAGtfzjbC7InUB76wRHiWX3Rc/j/p9bTc8SEREfUVhIg6g8Uc6qrHtwHX4fLNgQlkTzjDkkd+hqepqIiPiQoy5fPGnSJNLS0oiNjaV169Zcd911bNq0qb62SSNRtGUVe58f+M+oAJYmZNDtoa9oo6gQEWl06hQWixYtYtSoUSxbtozPP/+cmpoaLr/8csrLy+trnwS4gr9Opfncy+nq2cER4lh9yUzS73iF0LBw09NERKQeWLZt22d754MHD9K6dWsWLVrERRdddEb3KS0tJT4+npKSEuLi4s72ocXPnSg/zpqsu3Ae/QiAdeF9aD1sDq0SOpkdJiIiZ+VMX7/P6RqLkpISAJo3b37Kr6mqqqKqqup7w6Rx27WxEO87w3B6d+G1LXI7ZuLMeIaQUF3SIyLS2NXpVMi/83q9jB07loEDB9KrV69Tft2kSZOIj48/eUtMTDzbh5QAkP/+ZFrN/wWdvbs4RFPWX5ZD+sjnFRUiIkHirE+F3H333XzyySd88803dOjQ4ZRf90PvWCQmJupUSCNTUVbCuum3k1byKQBrIvrRbvgcWrZVSIqINAb1eirk3nvv5aOPPmLx4sU/GhUAERERRETog48asx3rcnG8N4I07x48tkVe57twDn5K71KIiAShOv3Lb9s2o0ePZsGCBXz11Vd07ty5vnZJALC9XvIX/Jk+qycSadVwgOYc+sXrpKdfaXqaiIgYUqewGDVqFG+++SYffPABsbGxFBcXAxAfH09UVFS9DBT/VFZ6lI1ZmThLvwALVkem0WFEDj1btzc9TUREDKrTNRaWZf3g8ezsbIYNG3ZGv4e+3TTwbVu9hPAFI0m091FrO8jvei+uQX/AERJiepqIiNSTernG4hw+8kIaAdvrJe/d5+m77jkirBqKacmxq98g3flz09NERMRP6Oo6OSOlxw6zNWs4rrJFYMHK6HQ6jZhF95ZtTU8TERE/orCQ09qyYjHRH2aSYu+nxg5h+QX34brtUSzHWX8MioiINFIKCzkl2+sl9+1JpGx8gXDLw3e0ovSaabhT/8f0NBER8VMKC/lBJUcOsj0rA3fFt2DBipif0GXkLNo1b2V6moiI+DGFhfyXTQVfEvfRHfTjINV2KIXdH8B1y3id+hARkdNSWMhJttdL7ptP0H/LK4RZHvZabai4bgbuvj81PU1ERAKEwkIAOHaomJ0zMnCfWAYWLG9yCd0yZ9K+aQvT00REJIAoLISNuZ/R7JO76MthquwwViY9jPPGB3TqQ0RE6kxhEcS8Hg+5cx8jbfvrhFpeiqwEqm/IxtXbbXqaiIgEKIVFkDq8fw97szNIrywACwriLqN7ZhZN4pqZniYiIgFMYRGE1i35mNaf3UMfjnLCDmdNn0dIu36MTn2IiMg5U1gEEU9tLXlzHsG5cyohls0uRyLeG7Nx9kwzPU1ERBoJhUWQOFS8m+LsIaRXrQQL8pteSVLmVKKbxJueJiIijYjCIgis/foD2i4cQy+OUWFHsK7f46RdN8r0LBERaYQUFo1YbU01BTnjcRbNxGHZ7HCch+PmWaR1TzE9TUREGimFRSN1cN9ODs4ajLt6DViQ1/wa+mS+QWR0E9PTRESkEVNYNEKr//EuiYvupyellNuRbEh9Auc1d5qeJSIiQUBh0YjU1lSTn/0A6ftmA7AtpDPht+aQ2i3Z8DIREQkWCotGorhoK0dnDyG9Zj0AuS1/TfLIyURGxRheJiIiwURh0QisXPgWnb5+gB6UcdyOYrNrEq6rhpueJSIiQUhhEcCqqyopnDkW9/75AGwJOZ/oQbPp3yXJ8DIREQlWCosAtW/nJo7PHYK7dhMAy1rdRL+RrxARGW14mYiIBDOFRQBa8dlcui55iATKKSWGbQOew335YNOzREREFBaBpKqyghUzxuA++BcANoVeSOzgOfTrdKHhZSIiIv+ksAgQe7evo2LeUNyerQAsa3MbKSNeJjwi0vAyERGR/09hEQCWf5zNBbkTaG+d4BhN2PnTF3BfeqvpWSIiIv9FYeHHKk+UsyrrHlyH3wcLNoT1pNnQOfRNPN/0NBERkR+ksPBTRVtWUf1WBi7PDgCWJmSQOuxPhIVHGF4mIiJyagoLP1Tw16n0KHiMGKuSo8RRdMnLpF9yg+lZIiIip6Ww8CMnyo+zJusunEc/AgvWhfem9bC59EnoZHqaiIjIGVFY+IldGwvxvjMMp3cXXtsiL3EEqRnPEBoWbnqaiIjIGVNY+IH89yeTtOIJoq0qDtGU7y59BfdF15qeJSIiUmcKC4MqykpYN/0O0kr+DhasjehL2+Fz6N22o+lpIiIiZ0VhYciO9fk43h1GmncPHtsir9OdOIdMJCRUT4mIiAQuvYo1MNvrJX/Bn+mzeiKRVg0HaM7BK14jfcBVpqeJiIicM4VFAyorPcrGrEycpV+ABasjU+kwYjZJrdubniYiIuITCosGsm31EsIXjCTV3ket7SC/yz24Bj+BIyTE9DQRERGfUVjUM9vrJe/d5+m77jkirBr204KjV71Buuty09NERER8TmFRj0qPHWZL1ghcZV+BBSuj3HQamUP3lm1NTxMREakXCot6smXl10R/MJL+9n5q7BCWdxuD6zePYTkcpqeJiIjUG4WFj9leL7lvP0PKxhcIt2r5jlaUXDMVd+qlpqeJiIjUO4WFD5UcOcj2GcNwl38DFqyIHkiXzBzaNW9lepqIiEiDUFj4yKaCL4n76A76cZBqO4TC7g/gumWCTn2IiEhQUVicI9vrJffNJ+i/5RXCLA97rTZUXJuFu99FpqeJiIg0OIXFOTh2qJidMzJwn1gGFhQ2uZjzM7Np37SF6WkiIiJGKCzO0sbcz2j6yd305RBVdhgrkx7CeeODOvUhIiJBTWFRR16Ph9y5j5G2/XVCLS9FVgLVv56Bq88A09NERESMU1jUwZEDe9kzM4P0ynywoCDuMrpnZtEkrpnpaSIiIn5BYXGG1i/9hJaf3kMfjlBph7G6z+9Ju36MTn2IiIj8G4XFaXhqa8mb8wjOnVMJsWx2OTrgvXEWzp5ppqeJiIj4HYXFjzhUvJvi7CGkV60EC/Ljf0HS7dOIbhJvepqIiIhfUlicwtqvP6DtwjH04hgVdgTr+j1G2nX3mp4lIiLi1xQW/8FTW0tezsO4ds/AYdnscJyH46Zs0nr0Nz1NRETE7yks/s3BfTs5MGsw6dVrwIK8Zr+kd+YbRMXEmp4mIiISEBQW/7L6q/fo8NVYkiil3I5kQ+oTOK+50/QsERGRgBL0YVFbU01+9gOk75sNwLaQzoTfmkNqt2TDy0RERAJPUIdFcdFWjs4eQnrNegByW1xHcubrREbFGF4mIiISmII2LFZ9+RbnLX6AHpRx3I5is2sirqtGmp4lIiIS0IIuLGqqq1g+837cxfMA2BJyPtGDZtO/S5LhZSIiIoEvqMLiu12bKJ0zBHftJgCWtbqJfiNfISIy2vAyERGRxiFowmLFZ3PpuuQh2lFOKTFsG/Ac7ssHm54lIiLSqDT6sKiqrGDFzPtwH3gHgE2hFxI7eA79Ol1oeJmIiEjj06jDYu/2DVTMG4zbsxWAZW1uI2XEy4RHRBpeJiIi0jid1c/8fu211+jUqRORkZG4XC7y8vJ8veucFX6STVzOz+jm2coxmrDyp1Nx3/2GokJERKQe1Tks3n77bcaNG8fjjz9OYWEhycnJXHHFFRw4cKA+9tVZ5YlycicPJyV3LLHWCTaE9aRy5CL6Xnqr6WkiIiKNnmXbtl2XO7hcLtLS0pg8eTIAXq+XxMRERo8ezfjx4097/9LSUuLj4ykpKSEuLu7sVp9C0dY1VM8fSlfPdgCWJmSQOuxPhIVH+PRxREREgs2Zvn7X6RqL6upqli9fzoQJE04eczgcXHbZZSxduvQH71NVVUVVVdX3htWHgo+m0SP/UWKsSo4SR9ElL5N+yQ318lgiIiLyw+p0KuTQoUN4PB7atGnzveNt2rShuLj4B+8zadIk4uPjT94SExPPfu0pHNi7g175vyPGqmRdeG9q7/iaPooKERGRBndWF2/WxYQJEygpKTl5Kyoq8vljtG7fmdV9HmFZh5Fc+NsvaZXQyeePISIiIqdXp1MhLVu2JCQkhP3793/v+P79+2nbtu0P3iciIoKIiPq/xsF5w/31/hgiIiLy4+r0jkV4eDj9+/dn4cKFJ495vV4WLlxIenq6z8eJiIhIYKnzB2SNGzeOjIwMUlNTcTqdvPzyy5SXlzN8+PD62CciIiIBpM5hccstt3Dw4EEee+wxiouL6du3L3//+9//64JOERERCT51/hyLc1Wfn2MhIiIi9eNMX7/r/btCREREJHgoLERERMRnFBYiIiLiMwoLERER8RmFhYiIiPiMwkJERER8RmEhIiIiPqOwEBEREZ9RWIiIiIjP1Pkjvc/V/33QZ2lpaUM/tIiIiJyl/3vdPt0Hdjd4WBw/fhyAxMTEhn5oEREROUfHjx8nPj7+lL/e4D8rxOv1sm/fPmJjY7Esy2e/b2lpKYmJiRQVFelnkPgBPR/+R8+Jf9Hz4V/0fJyebdscP36chIQEHI5TX0nR4O9YOBwOOnToUG+/f1xcnP6n8CN6PvyPnhP/oufDv+j5+HE/9k7F/9HFmyIiIuIzCgsRERHxmUYTFhERETz++ONERESYniLo+fBHek78i54P/6Lnw3ca/OJNERERabwazTsWIiIiYp7CQkRERHxGYSEiIiI+o7AQERERn2k0YfHaa6/RqVMnIiMjcblc5OXlmZ4UlCZNmkRaWhqxsbG0bt2a6667jk2bNpmeJf/yzDPPYFkWY8eONT0laO3du5fBgwfTokULoqKi6N27NwUFBaZnBS2Px8Ojjz5K586diYqKomvXrjz55JOn/XkYcmqNIizefvttxo0bx+OPP05hYSHJyclcccUVHDhwwPS0oLNo0SJGjRrFsmXL+Pzzz6mpqeHyyy+nvLzc9LSgl5+fz9SpU+nTp4/pKUHr6NGjDBw4kLCwMD755BPWr1/PCy+8QLNmzUxPC1rPPvssU6ZMYfLkyWzYsIFnn32W5557jldffdX0tIDVKL7d1OVykZaWxuTJk4F//jySxMRERo8ezfjx4w2vC24HDx6kdevWLFq0iIsuusj0nKBVVlZGSkoKr7/+Ok899RR9+/bl5ZdfNj0r6IwfP55vv/2Wr7/+2vQU+Zdf/vKXtGnThhkzZpw8dsMNNxAVFcXcuXMNLgtcAf+ORXV1NcuXL+eyyy47eczhcHDZZZexdOlSg8sEoKSkBIDmzZsbXhLcRo0axdVXX/29vyfS8D788ENSU1O56aabaN26Nf369WP69OmmZwW1AQMGsHDhQjZv3gzAqlWr+Oabb7jyyisNLwtcDf5DyHzt0KFDeDwe2rRp873jbdq0YePGjYZWCfzznaOxY8cycOBAevXqZXpO0HrrrbcoLCwkPz/f9JSgt337dqZMmcK4ceP43e9+R35+PmPGjCE8PJyMjAzT84LS+PHjKS0tpXv37oSEhODxeJg4cSKDBg0yPS1gBXxYiP8aNWoUa9eu5ZtvvjE9JWgVFRVx33338fnnnxMZGWl6TtDzer2kpqby9NNPA9CvXz/Wrl3LG2+8obAw5J133mHevHm8+eabJCUlsXLlSsaOHUtCQoKek7MU8GHRsmVLQkJC2L9///eO79+/n7Zt2xpaJffeey8fffQRixcvpkOHDqbnBK3ly5dz4MABUlJSTh7zeDwsXryYyZMnU1VVRUhIiMGFwaVdu3b07Nnze8d69OjBe++9Z2iR/Pa3v2X8+PHceuutAPTu3Ztdu3YxadIkhcVZCvhrLMLDw+nfvz8LFy48eczr9bJw4ULS09MNLgtOtm1z7733smDBAr788ks6d+5selJQu/TSS1mzZg0rV648eUtNTWXQoEGsXLlSUdHABg4c+F/ffr1582bOO+88Q4ukoqICh+P7L4UhISF4vV5DiwJfwL9jATBu3DgyMjJITU3F6XTy8ssvU15ezvDhw01PCzqjRo3izTff5IMPPiA2Npbi4mIA4uPjiYqKMrwu+MTGxv7X9S0xMTG0aNFC170YcP/99zNgwACefvppbr75ZvLy8pg2bRrTpk0zPS1oXXPNNUycOJGOHTuSlJTEihUrePHFFxkxYoTpaYHLbiReffVVu2PHjnZ4eLjtdDrtZcuWmZ4UlIAfvGVnZ5ueJv9y8cUX2/fdd5/pGUHrr3/9q92rVy87IiLC7t69uz1t2jTTk4JaaWmpfd9999kdO3a0IyMj7S5dutiPPPKIXVVVZXpawGoUn2MhIiIi/iHgr7EQERER/6GwEBEREZ9RWIiIiIjPKCxERETEZxQWIiIi4jMKCxEREfEZhYWIiIj4jMJCREREfEZhISIiIj6jsBARERGfUViIiIiIzygsRERExGf+H92ZM85WR7M0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs, [x for x in range(len(accs))])\n",
    "plt.plot(loss, [x for x in range(len(losses))])\n",
    "plt.savefig('evaluation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dataset = get_from_csv('/home/kuro/PycharmProjects/sequence_tagging/NLP2/data/val.txt')\n",
    "rank = bm25(dataset)\n",
    "del dataset\n",
    "gc.collect()\n",
    "dataset = prep_data(rank)\n",
    "questions = dataset['question'].to_list()\n",
    "contexts = dataset['context'].to_list()\n",
    "answers = dataset['answer']\n",
    "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "train_encoding = tokenizer(contexts, questions, truncation=True, padding=True, max_length=512)\n",
    "train_encoding['answers'] = answers\n",
    "dataset = Dataset(train_encoding)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(answers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vall_loss = []\n",
    "vall_acc = []\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_batch)\n",
    "acc = []\n",
    "loss = []\n",
    "for epoch in range(50):\n",
    "    loop = tqdm(loader)\n",
    "    for a, b, c, d in loop:\n",
    "        with torch.no_grad():\n",
    "            input_ids = torch.as_tensor(a).to(device)\n",
    "            attention_mask = torch.as_tensor(b).to(device)\n",
    "            start_positions = torch.as_tensor(c).to(device)\n",
    "            end_positions = torch.as_tensor(d).to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            start_positions=start_positions,\n",
    "                            end_positions=end_positions)\n",
    "\n",
    "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "            acc.append(((start_pred == start_positions).sum() / len(start_pred)).item())\n",
    "            acc.append(((end_pred == end_positions).sum() / len(end_pred)).item())\n",
    "\n",
    "            loss = outputs['loss']\n",
    "            vall_loss.append(loss.item())\n",
    "            print(f'Epoch {epoch} loss {loss.item()}')\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(acc, [x for x in range(0, len(acc))])\n",
    "plt.plot(vall_loss, [x for x in range(0, len(vall_loss))])\n",
    "plt.savefig('evaluation')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
